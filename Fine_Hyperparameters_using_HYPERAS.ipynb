{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenneth\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\kenneth\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adadelta\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from collections import Counter\n",
    "import operator\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import hyperas\n",
    "import hyperopt\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 50\n",
    "#BATCH_SIZE = 254\n",
    "#BATCH_SIZE ={{choice([128,512])}}\n",
    "VERBOSE = 2\n",
    "#NB_CLASSES = 2   # number of outputs = number of digits\n",
    "# OPTIMIZER = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0000001, amsgrad=False) \n",
    "#Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "#OPTIMIZER=Adadelta(lr=0.8, rho=0.95, epsilon=None, decay=0.0)\n",
    "#gradient clipping clipnorm=1.  maximum norm of 1.\n",
    "#clipvalue=0.5 ......max=0.5 and min=-0.5\n",
    "OPTIMIZER = Adam(lr=3e-4) \n",
    "#OPTIMIZER ={{choice(['rmsprop', 'adam','sgd'])}}\n",
    "N_HIDDEN = 254\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.5\n",
    "MODEL_DIR = 'model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    x=pd.read_csv('df.csv', index_col=0, parse_dates=True)\n",
    "    x_pred = pd.read_csv('x_pred.csv', index_col=0, parse_dates=True)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    x_scaler=StandardScaler()\n",
    "    x = x_scaler.fit_transform(x)\n",
    "    x_pred = x_scaler.fit_transform(x_pred)\n",
    "    y=pd.read_csv('y.csv', index_col=0, parse_dates=True, names=['label'])\n",
    "    x_train, x_test, y_train, y_test=cross_validation.train_test_split(x,y,test_size=0.1, random_state=54)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_pred = x_pred.astype('float32')\n",
    "    NB_CLASSES = 2 \n",
    "    y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "    y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense({{choice([64,128, 256, 512])}},input_shape=(x_train.shape[1],),\n",
    "              kernel_regularizer=regularizers.l2({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}),\n",
    "              bias_regularizer=regularizers.l1({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}))\n",
    "             )\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([64,128, 256, 512])}}), \n",
    "#               kernel_regularizer=regularizers.l2({{choice([0.01,0.02, 0.03, 0.04, 0.05])}}),\n",
    "#               bias_regularizer=regularizers.l1({{choice([0.01,0.02, 0.03, 0.04, 0.05])}})\n",
    "             )\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([64,128, 256, 512])}}), \n",
    "#               kernel_regularizer=regularizers.l2({{choice([0.01,0.02, 0.03, 0.04, 0.05])}}),\n",
    "#               bias_regularizer=regularizers.l1({{choice([0.01,0.02, 0.03, 0.04, 0.05])}})\n",
    "             )\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], \n",
    "                  optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, \n",
    "                                 decay=0.000001, amsgrad=False) \n",
    "                 )\n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "              batch_size={{choice([128, 254, 512])}},\n",
    "              epochs=100,\n",
    "              verbose=0,\n",
    "              validation_split=0.1)\n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Activation, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import SGD, RMSprop, Adam, Adadelta\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import cross_validation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import regularizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import ModelCheckpoint\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from collections import Counter\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import operator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import roc_auc_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import itertools\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import hyperas\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import hyperopt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [64,128, 256, 512]),\n",
      "        'l2': hp.choice('l2', [0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]),\n",
      "        'l2_1': hp.choice('l2_1', [0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense_1': hp.choice('Dense_1', [64,128, 256, 512]),\n",
      "        'l2_2': hp.choice('l2_2', [0.01,0.02, 0.03, 0.04, 0.05]),\n",
      "        'l2_3': hp.choice('l2_3', [0.01,0.02, 0.03, 0.04, 0.05]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'Dense_2': hp.choice('Dense_2', [64,128, 256, 512]),\n",
      "        'l2_4': hp.choice('l2_4', [0.01,0.02, 0.03, 0.04, 0.05]),\n",
      "        'l2_5': hp.choice('l2_5', [0.01,0.02, 0.03, 0.04, 0.05]),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'batch_size': hp.choice('batch_size', [128, 254, 512]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: x=pd.read_csv('d:/kenneth/keras/data/df.csv', index_col=0, parse_dates=True)\n",
      "  3: x_pred = pd.read_csv('d:/kenneth/keras/data/x_pred.csv', index_col=0, parse_dates=True)\n",
      "  4: from sklearn.preprocessing import StandardScaler\n",
      "  5: x_scaler=StandardScaler()\n",
      "  6: x = x_scaler.fit_transform(x)\n",
      "  7: x_pred = x_scaler.fit_transform(x_pred)\n",
      "  8: y=pd.read_csv('d:/kenneth/keras/data/y.csv', index_col=0, parse_dates=True, names=['label'])\n",
      "  9: x_train, x_test, y_train, y_test=cross_validation.train_test_split(x,y,test_size=0.1, random_state=54)\n",
      " 10: x_train = x_train.astype('float32')\n",
      " 11: x_test = x_test.astype('float32')\n",
      " 12: x_pred = x_pred.astype('float32')\n",
      " 13: NB_CLASSES = 2 \n",
      " 14: y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
      " 15: y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
      " 16: \n",
      " 17: \n",
      " 18: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     model = Sequential()\n",
      "   4:     model.add(Dense(space['Dense'],input_shape=(x_train.shape[1],),\n",
      "   5:               kernel_regularizer=regularizers.l2(space['l2']),\n",
      "   6:               bias_regularizer=regularizers.l1(space['l2_1']))\n",
      "   7:              )\n",
      "   8:     model.add(Activation('relu'))\n",
      "   9:     model.add(Dropout(space['Dropout']))\n",
      "  10:     model.add(Dense(space['Dense_1']), \n",
      "  11: #               kernel_regularizer=regularizers.l2(space['l2_2']),\n",
      "  12: #               bias_regularizer=regularizers.l1(space['l2_3'])\n",
      "  13:              )\n",
      "  14:     model.add(Activation('relu'))\n",
      "  15:     model.add(Dropout(space['Dropout_1']))\n",
      "  16:     model.add(Dense(space['Dense_2']), \n",
      "  17: #               kernel_regularizer=regularizers.l2(space['l2_4']),\n",
      "  18: #               bias_regularizer=regularizers.l1(space['l2_5'])\n",
      "  19:              )\n",
      "  20:     model.add(Activation('relu'))\n",
      "  21:     model.add(Dropout(space['Dropout_2']))\n",
      "  22:     \n",
      "  23: \n",
      "  24: \n",
      "  25:     model.add(Dense(2))\n",
      "  26:     model.add(Activation('softmax'))\n",
      "  27: \n",
      "  28:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'], \n",
      "  29:                   optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, \n",
      "  30:                                  decay=0.000001, amsgrad=False) \n",
      "  31:                  )\n",
      "  32: \n",
      "  33:     result = model.fit(x_train, y_train,\n",
      "  34:               batch_size=space['batch_size'],\n",
      "  35:               epochs=100,\n",
      "  36:               verbose=0,\n",
      "  37:               validation_split=0.1)\n",
      "  38:     #get the highest validation accuracy of the training epochs\n",
      "  39:     validation_acc = np.amax(result.history['val_acc']) \n",
      "  40:     print('Best validation acc of epoch:', validation_acc)\n",
      "  41:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      "  42: \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.594138545634268                                                                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5719360565207567                                                                                                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5710479662642809                                                                                                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5710479570536164                                                                                                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5710479570536164                                                                                                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5710479570536164                                                                                                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5710479570536164                                                                                                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5728241587405095                                                                                                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5719360565207567                                                                                                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "0.5710479570536164                                                                                                     \n",
      "100%|███████████████████████████████████████████████████| 10/10 [08:52<00:00, 50.85s/it, best loss: -0.594138545634268]\n",
      "Evalutation of best performing model:\n",
      "1251/1251 [==============================] - ETA:  - ETA:  - ETA:  - 0s 96us/step\n",
      "[0.7340535161306532, 0.5619504396482814]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'l2_1': 5, 'Dropout_1': 0.039825089762879906, 'l2': 9, 'l2_3': 3, 'Dense_2': 2, 'Dropout_2': 0.11245974166556161, 'Dense': 2, 'Dropout': 0.44390441345306564, 'l2_2': 1, 'batch_size': 2, 'l2_4': 0, 'l2_5': 1, 'Dense_1': 0}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   \n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=10,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='testing_hyperas_2'\n",
    "                                         )\n",
    "    x_train, y_train, x_test, y_test  = data()\n",
    "\n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    print(best_model.evaluate(x_test, y_test))\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
